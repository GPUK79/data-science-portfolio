{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # Visualization\n",
    "import seaborn as sns #Visualization\n",
    "plt.rcParams['figure.figsize'] = [8,5]\n",
    "plt.rcParams['font.size'] =14\n",
    "plt.rcParams['font.weight']= 'bold'\n",
    "import scipy \n",
    "from scipy import stats \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, accuracy_score, auc\n",
    "import statsmodels.formula.api as smf\n",
    "import math\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, GroupKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def calculate_thresholds(n_records, n_bads, n_goods):\n",
    "    # Total threshold\n",
    "    if n_records <= 3000: tot_thresh = 0.1\n",
    "    elif n_records > 3000 and n_records <= 5000: tot_thresh = 0.05\n",
    "    elif n_records > 5000 and n_records <= 20000: tot_thresh = 0.03\n",
    "    elif n_records > 20000 and n_records <= 50000: tot_thresh = 0.01\n",
    "    else: tot_thresh = 0.005\n",
    "    # Bad threshold\n",
    "    if n_bads <= 3000: bad_thresh = 0.10\n",
    "    elif n_bads > 3000 and n_bads <= 5000: bad_thresh = 0.05\n",
    "    elif n_bads > 5000 and n_bads <= 20000: bad_thresh = 0.03\n",
    "    elif n_bads > 20000 and n_bads <= 50000: bad_thresh = 0.01\n",
    "    else:bad_thresh = 0.005\n",
    "    # Good threshold\n",
    "    if n_goods <= 3000: good_thresh = 0.10\n",
    "    elif n_goods > 3000 and n_goods <= 5000: good_thresh = 0.05\n",
    "    elif n_goods > 5000 and n_goods <= 20000: good_thresh = 0.03\n",
    "    elif n_goods > 20000 and n_goods <= 50000: good_thresh = 0.01\n",
    "    else: good_thresh = 0.005\n",
    "    return tot_thresh, bad_thresh, good_thresh\n",
    "\n",
    "def calculate_scorecard(d1, char):\n",
    "    d2 = d1.groupby([char], dropna=False)\n",
    "    d3 = pd.DataFrame(d2[\"X\"].min(), columns=[\"min\"])\n",
    "    d3[\"# Good\"] = d2[\"Y\"].sum()\n",
    "    d3[\"# Bad\"] = d2[\"Y\"].count() - d3[\"# Good\"]\n",
    "    d3[\"% Good\"] = round(d3[\"# Good\"] / d3[\"# Good\"].sum() * 100, 1)\n",
    "    d3[\"% Bad\"] = round(d3[\"# Bad\"] / d3[\"# Bad\"].sum() * 100, 1)\n",
    "    d3[\"# Total\"] = d2[\"Y\"].count()\n",
    "    d3[\"% Total\"] = round(d3[\"# Total\"] / d3[\"# Total\"].sum() * 100, 1)\n",
    "    d3[\"Information Odds\"] = round(d3[\"% Good\"] / d3[\"% Bad\"], 2)\n",
    "    d3[\"Bad Rate\"] = round(d3[\"# Bad\"] / (d3[\"# Bad\"] + d3[\"# Good\"]) * 100, 2)\n",
    "    d3[\"WoE\"] = round(np.log(d3[\"% Good\"] / d3[\"% Bad\"]), 2)\n",
    "    iv = (d3[\"% Good\"] - d3[\"% Bad\"]) * d3[\"WoE\"] / 100\n",
    "    d4 = d3.sort_index().drop(columns=[\"min\"], axis=1)\n",
    "\n",
    "    return d4, iv\n",
    "\n",
    "def featureMonotonicBinning(Y, X, char):\n",
    "    r = 0\n",
    "    bad_flag = 0\n",
    "    n = 20\n",
    "    while np.abs(r) != 1 and bad_flag == 0:\n",
    "        d1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
    "        d1[\"Value\"], bins = pd.qcut(d1[\"X\"], n, duplicates=\"drop\", retbins=True, precision=3)\n",
    "        if len(bins) == 2:\n",
    "            bins = bins.tolist()\n",
    "            bins.insert(0, float(\"-inf\"))\n",
    "            bins.append(float(\"+inf\"))\n",
    "            d1[\"Value\"] = pd.cut(d1[\"X\"], bins=bins, precision=3, include_lowest=True)\n",
    "        d2 = d1.groupby(\"Value\", as_index=True)\n",
    "        r,p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n",
    "        d3, iv = calculate_scorecard(d1, \"Value\")\n",
    "        d3.dropna(inplace=True)\n",
    "        \n",
    "        if len(d3) < 3:\n",
    "            bad_flag = 1\n",
    "        n = n-1\n",
    "       \n",
    "    pctThresh, badThresh, goodThresh = calculate_thresholds(d3[\"# Total\"].sum(),d3[\"# Bad\"].sum(),d3[\"# Good\"].sum())\n",
    "    condition = [(d3[\"% Total\"] < pctThresh*100) | (d3[\"% Bad\"] < badThresh*100) | (d3[\"% Good\"] < goodThresh*100)]\n",
    "    d3[\"Not Robust\"] = np.select(condition, [1], 0)\n",
    "    criteria = d3[\"Not Robust\"].sum()\n",
    "    d3 = d3.reset_index()\n",
    "    while criteria > 0:\n",
    "        i = d3[d3[\"Not Robust\"] == 1].index[0]\n",
    "        #if first row -> merge two first categories\n",
    "        if i == 0:\n",
    "            bins = np.delete(bins, 1)\n",
    "        # if last row -> merge two last categories\n",
    "        elif i == (len(d3) - 1):\n",
    "            bins = np.delete(bins, len(d3)-1)\n",
    "        else:\n",
    "            # if number of samples greater in former -> merge with latter\n",
    "            if (d3.at[i-1 , \"# Total\"] > d3.at[i+1 , \"# Total\"]):\n",
    "                bins = np.delete(bins, i+1)\n",
    "            # if number of samples greater in latter -> merge with former\n",
    "            else:\n",
    "                bins = np.delete(bins, i)        \n",
    "        d1 = pd.DataFrame({\"X\": X, \"Y\": Y, \"Value\": pd.cut(X, bins, precision=3, include_lowest=True)})\n",
    "        d3, iv = calculate_scorecard(d1, \"Value\")\n",
    "        condition = [\n",
    "            (d3[\"% Total\"] < pctThresh*100) | \n",
    "            (d3[\"% Bad\"] < badThresh*100) | \n",
    "            (d3[\"% Good\"] < goodThresh*100) ]\n",
    "        d3[\"Not Robust\"] = np.select(condition, [1], 0)\n",
    "        criteria = d3[\"Not Robust\"].sum()\n",
    "        d3 = d3.reset_index()\n",
    "    d3 = d3.drop(columns=[\"Not Robust\"])\n",
    "    infValue = round(iv.sum(),3)\n",
    "\n",
    "    ax1 = d3.plot.bar(x='Value', y='WoE', rot=0)\n",
    "    ax1.legend(\"\")\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=9)\n",
    "    ax1.set_title(\"Train Sample - \"+char+\" WoE - Inf. Value: \" + str(infValue), fontsize=10)\n",
    "    ax1.set_xlabel(char, fontsize = 10)\n",
    "    ax1.set_ylabel(\"Weight of Evidence\", fontsize = 10)\n",
    "    display(d3)\n",
    "    return d3, iv, infValue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def featureMonotonicBinning(Y, X, char):\n",
    "    r = 0\n",
    "    bad_flag = 0\n",
    "    n = 20\n",
    "    while np.abs(r) != 1 and bad_flag == 0:\n",
    "        d1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
    "        d1[\"Value\"], bins = pd.qcut(d1[\"X\"], n, duplicates=\"drop\", retbins=True, precision=3)\n",
    "        if len(bins) == 2:\n",
    "            bins = bins.tolist()\n",
    "            bins.insert(0, float(\"-inf\"))\n",
    "            bins.append(float(\"+inf\"))\n",
    "            d1[\"Value\"] = pd.cut(d1[\"X\"], bins=bins, precision=3, include_lowest=True)\n",
    "        d2 = d1.groupby(\"Value\", as_index=True)\n",
    "        r,p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n",
    "        d3, iv = calculate_scorecard(d1, \"Value\")\n",
    "        d3.dropna(inplace=True)\n",
    "        \n",
    "        if len(d3) < 3:\n",
    "            bad_flag = 1\n",
    "        n = n-1\n",
    "       \n",
    "    pctThresh, badThresh, goodThresh = calculate_thresholds(d3[\"# Total\"].sum(),d3[\"# Bad\"].sum(),d3[\"# Good\"].sum())\n",
    "    condition = [(d3[\"% Total\"] < pctThresh*100) | (d3[\"% Bad\"] < badThresh*100) | (d3[\"% Good\"] < goodThresh*100)]\n",
    "    d3[\"Not Robust\"] = np.select(condition, [1], 0)\n",
    "    criteria = d3[\"Not Robust\"].sum()\n",
    "    d3 = d3.reset_index()\n",
    "    while criteria > 0:\n",
    "        i = d3[d3[\"Not Robust\"] == 1].index[0]\n",
    "        #if first row -> merge two first categories\n",
    "        if i == 0:\n",
    "            bins = np.delete(bins, 1)\n",
    "        # if last row -> merge two last categories\n",
    "        elif i == (len(d3) - 1):\n",
    "            bins = np.delete(bins, len(d3)-1)\n",
    "        else:\n",
    "            # if number of samples greater in former -> merge with latter\n",
    "            if (d3.at[i-1 , \"# Total\"] > d3.at[i+1 , \"# Total\"]):\n",
    "                bins = np.delete(bins, i+1)\n",
    "            # if number of samples greater in latter -> merge with former\n",
    "            else:\n",
    "                bins = np.delete(bins, i)        \n",
    "        d1 = pd.DataFrame({\"X\": X, \"Y\": Y, \"Value\": pd.cut(X, bins, precision=3, include_lowest=True)})\n",
    "        d3, iv = calculate_scorecard(d1, \"Value\")\n",
    "        condition = [\n",
    "            (d3[\"% Total\"] < pctThresh*100) | \n",
    "            (d3[\"% Bad\"] < badThresh*100) | \n",
    "            (d3[\"% Good\"] < goodThresh*100) ]\n",
    "        d3[\"Not Robust\"] = np.select(condition, [1], 0)\n",
    "        criteria = d3[\"Not Robust\"].sum()\n",
    "        d3 = d3.reset_index()\n",
    "    d3 = d3.drop(columns=[\"Not Robust\"])\n",
    "    infValue = round(iv.sum(),3)\n",
    "    display(d3)\n",
    "    ax1 = d3.plot.bar(x='Value', y='WoE', rot=0)\n",
    "    ax1.legend(\"\")\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=9)\n",
    "    ax1.set_title(\"Train Sample - \"+char+\" WoE - Inf. Value: \" + str(infValue), fontsize=10)\n",
    "    ax1.set_xlabel(char, fontsize = 10)\n",
    "    ax1.set_ylabel(\"Weight of Evidence\", fontsize = 10)\n",
    "    return d3, iv, infValue\n",
    "\n",
    "\n",
    "\n",
    "def fMb(Y, X, char):\n",
    "    r = 0\n",
    "    bad_flag = 0\n",
    "    n = 20\n",
    "    while np.abs(r) != 1 and bad_flag == 0:\n",
    "        d1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
    "        d1[\"Value\"], bins = pd.qcut(d1[\"X\"], n, duplicates=\"drop\", retbins=True, precision=3)\n",
    "        if len(bins) == 2:\n",
    "            bins = bins.tolist()\n",
    "            bins.insert(0, float(\"-inf\"))\n",
    "            bins.append(float(\"+inf\"))\n",
    "            d1[\"Value\"] = pd.cut(d1[\"X\"], bins=bins, precision=3, include_lowest=True)\n",
    "        d2 = d1.groupby(\"Value\", as_index=True)\n",
    "        r,p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n",
    "        d3, iv = calculate_scorecard(d1, \"Value\")\n",
    "        d3.dropna(inplace=True)\n",
    "        \n",
    "        if len(d3) < 3:\n",
    "            bad_flag = 1\n",
    "        n = n-1\n",
    "       \n",
    "    pctThresh, badThresh, goodThresh = calculate_thresholds(d3[\"# Total\"].sum(),d3[\"# Bad\"].sum(),d3[\"# Good\"].sum())\n",
    "    condition = [(d3[\"% Total\"] < pctThresh*100) | (d3[\"% Bad\"] < badThresh*100) | (d3[\"% Good\"] < goodThresh*100)]\n",
    "    d3[\"Not Robust\"] = np.select(condition, [1], 0)\n",
    "    criteria = d3[\"Not Robust\"].sum()\n",
    "    d3 = d3.reset_index()\n",
    "    while criteria > 0:\n",
    "        i = d3[d3[\"Not Robust\"] == 1].index[0]\n",
    "        #if first row -> merge two first categories\n",
    "        if i == 0:\n",
    "            bins = np.delete(bins, 1)\n",
    "        # if last row -> merge two last categories\n",
    "        elif i == (len(d3) - 1):\n",
    "            bins = np.delete(bins, len(d3)-1)\n",
    "        else:\n",
    "            # if number of samples greater in former -> merge with latter\n",
    "            if (d3.at[i-1 , \"# Total\"] > d3.at[i+1 , \"# Total\"]):\n",
    "                bins = np.delete(bins, i+1)\n",
    "            # if number of samples greater in latter -> merge with former\n",
    "            else:\n",
    "                bins = np.delete(bins, i)        \n",
    "        d1 = pd.DataFrame({\"X\": X, \"Y\": Y, \"Value\": pd.cut(X, bins, precision=3, include_lowest=True)})\n",
    "        d3, iv = calculate_scorecard(d1, \"Value\")\n",
    "        condition = [\n",
    "            (d3[\"% Total\"] < pctThresh*100) | \n",
    "            (d3[\"% Bad\"] < badThresh*100) | \n",
    "            (d3[\"% Good\"] < goodThresh*100) ]\n",
    "        d3[\"Not Robust\"] = np.select(condition, [1], 0)\n",
    "        criteria = d3[\"Not Robust\"].sum()\n",
    "        d3 = d3.reset_index()\n",
    "    d3 = d3.drop(columns=[\"Not Robust\"])\n",
    "    infValue = round(iv.sum(),3)\n",
    "    return d3, iv, infValue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Weight Of Evidence (WOE) LOGISTIC REGRSSION SCORECARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: CL=F\n",
      "Start Date:  1924-06-12\n",
      "End Date:  2024-05-18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-08-23</td>\n",
       "      <td>31.950001</td>\n",
       "      <td>32.799999</td>\n",
       "      <td>31.950001</td>\n",
       "      <td>32.049999</td>\n",
       "      <td>32.049999</td>\n",
       "      <td>79385</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-08-24</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>32.240002</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>31.629999</td>\n",
       "      <td>31.629999</td>\n",
       "      <td>72978</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-08-25</td>\n",
       "      <td>31.700001</td>\n",
       "      <td>32.099998</td>\n",
       "      <td>31.320000</td>\n",
       "      <td>32.049999</td>\n",
       "      <td>32.049999</td>\n",
       "      <td>44601</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-08-28</td>\n",
       "      <td>32.040001</td>\n",
       "      <td>32.919998</td>\n",
       "      <td>31.860001</td>\n",
       "      <td>32.869999</td>\n",
       "      <td>32.869999</td>\n",
       "      <td>46770</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-08-29</td>\n",
       "      <td>32.820000</td>\n",
       "      <td>33.029999</td>\n",
       "      <td>32.560001</td>\n",
       "      <td>32.720001</td>\n",
       "      <td>32.720001</td>\n",
       "      <td>49131</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955</th>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>78.180000</td>\n",
       "      <td>79.489998</td>\n",
       "      <td>77.779999</td>\n",
       "      <td>79.120003</td>\n",
       "      <td>79.120003</td>\n",
       "      <td>287701</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5956</th>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>79.230003</td>\n",
       "      <td>79.379997</td>\n",
       "      <td>77.680000</td>\n",
       "      <td>78.019997</td>\n",
       "      <td>78.019997</td>\n",
       "      <td>307410</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>78.440002</td>\n",
       "      <td>78.919998</td>\n",
       "      <td>76.699997</td>\n",
       "      <td>78.629997</td>\n",
       "      <td>78.629997</td>\n",
       "      <td>321267</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5958</th>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>78.839996</td>\n",
       "      <td>79.849998</td>\n",
       "      <td>78.199997</td>\n",
       "      <td>79.230003</td>\n",
       "      <td>79.230003</td>\n",
       "      <td>230277</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5959</th>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>79.379997</td>\n",
       "      <td>80.139999</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>80.059998</td>\n",
       "      <td>80.059998</td>\n",
       "      <td>230277</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5960 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Open       High        Low      Close  Adj Close  \\\n",
       "0    2000-08-23  31.950001  32.799999  31.950001  32.049999  32.049999   \n",
       "1    2000-08-24  31.900000  32.240002  31.400000  31.629999  31.629999   \n",
       "2    2000-08-25  31.700001  32.099998  31.320000  32.049999  32.049999   \n",
       "3    2000-08-28  32.040001  32.919998  31.860001  32.869999  32.869999   \n",
       "4    2000-08-29  32.820000  33.029999  32.560001  32.720001  32.720001   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "5955 2024-05-13  78.180000  79.489998  77.779999  79.120003  79.120003   \n",
       "5956 2024-05-14  79.230003  79.379997  77.680000  78.019997  78.019997   \n",
       "5957 2024-05-15  78.440002  78.919998  76.699997  78.629997  78.629997   \n",
       "5958 2024-05-16  78.839996  79.849998  78.199997  79.230003  79.230003   \n",
       "5959 2024-05-17  79.379997  80.139999  79.000000  80.059998  80.059998   \n",
       "\n",
       "      Volume  Year  Month  Day  \n",
       "0      79385  2000      8   23  \n",
       "1      72978  2000      8   24  \n",
       "2      44601  2000      8   25  \n",
       "3      46770  2000      8   28  \n",
       "4      49131  2000      8   29  \n",
       "...      ...   ...    ...  ...  \n",
       "5955  287701  2024      5   13  \n",
       "5956  307410  2024      5   14  \n",
       "5957  321267  2024      5   15  \n",
       "5958  230277  2024      5   16  \n",
       "5959  230277  2024      5   17  \n",
       "\n",
       "[5960 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = 'CL=F'\n",
    "no_years = 100\n",
    "\n",
    "end_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.datetime.now() -\n",
    "              datetime.timedelta(days=no_years * 365)).strftime('%Y-%m-%d')\n",
    "\n",
    "print('Ticker: {}'.format(ticker))\n",
    "print('Start Date: ', start_date)\n",
    "print('End Date: ', end_date)\n",
    "\n",
    "df = get_price(ticker, start_date, end_date)\n",
    "closed_dates_list = get_closed_dates(df)\n",
    "\n",
    "df['Year'] = df['Date'].astype(str).str[0:4].astype(int)\n",
    "df['Month'] = df['Date'].astype(str).str[5:7].astype(int)\n",
    "df['Day'] = df['Date'].astype(str).str[8:10].astype(int)\n",
    "\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
