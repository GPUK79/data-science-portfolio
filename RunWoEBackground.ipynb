{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "import pickle\n",
    "from o3_Run_WoE_AnalysisAndTrainModel import MIV,test2015, fileName, inputData, chars, binners, charsAnalsysis, replaceWoe, runWoEAnalysis, replaceWoe, correlationsAnalysis, col_list, trainModel, modelDevelopment, scaleModel, loc\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from datetime import datetime\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "       \n",
    "\n",
    "ninf = float('-inf')\n",
    "pinf = float('+inf')  \n",
    "\n",
    "def render_iv_table(data, col_width=3.0, row_height=0.625, font_size=14.5,\n",
    "                     header_color='#33B3FF', row_colors=['#f1f1f2', 'w'], edge_color='w',\n",
    "                     bbox=[0, 0, 1, 1], header_columns=0,\n",
    "                     ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "        fig, ax = plt.subplots(figsize=size)\n",
    "        ax.axis('off')\n",
    "    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "\n",
    "    for k, cell in mpl_table._cells.items():\n",
    "        cell.set_edgecolor(edge_color)\n",
    "        if k[0] == 0 or k[1] < header_columns:\n",
    "            cell.set_text_props(weight='bold', color='w')\n",
    "            cell.set_facecolor(header_color)\n",
    "        else:\n",
    "            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])\n",
    "    return ax.get_figure(), ax\n",
    "\n",
    "def self_bin_char(Y,X):\n",
    "   good = Y.sum()\n",
    "   bad = Y.count()-good\n",
    "   d1=pd.DataFrame({'X':X,'Y':Y,chars[z]:X})\n",
    "   d2=d1.groupby([chars[z]],dropna=False)\n",
    "   d3=pd.DataFrame(d2['X'].min(),columns=['min'])\n",
    "   \n",
    "   d3['# Good']=d2['Y'].sum()\n",
    "   d3['# Bad']=d2['Y'].count()-d3['# Good']\n",
    "   d3['% Good'] = round(d3['# Good']/d3['# Good'].sum()*100,1)\n",
    "   d3['% Bad'] = round(d3['# Bad']/d3['# Bad'].sum()*100,1)\n",
    "   d3['# Total']=d2['Y'].count()\n",
    "   d3['% Total'] = round(d3['# Total']/d3['# Total'].sum()*100,1)\n",
    "   \n",
    "   d3['Information Odds'] = round(d3['% Good'] / d3['% Bad'],2)\n",
    "   d3['Bad Rate'] = round(d3['# Bad']/(d3['# Bad']+d3['# Good'])*100,2)\n",
    "   \n",
    "   d3['WoE'] = round(np.log(d3['% Good']/d3['% Bad']),2)\n",
    "   iv = ((d3['% Good']-d3['% Bad'])*d3['WoE']/100)\n",
    "   d4=d3.sort_index()\n",
    "   d4 = d3.drop(columns=['min'], axis=1)\n",
    "   woe = list(d3['WoE'].values)\n",
    "   \n",
    "   return d4,iv,woe\n",
    "   \n",
    "def self_bin(Y,X,cat):\n",
    "    d1=pd.DataFrame({'X':X,'Y':Y,chars[z]:pd.cut(X,cat)})\n",
    "    d2=d1.groupby([chars[z]],dropna=False)\n",
    "   \n",
    "    d3=pd.DataFrame(d2['X'].min(),columns=['min'])\n",
    "     \n",
    "    d3['# Good']=d2['Y'].sum()\n",
    "    d3['# Bad']=d2['Y'].count()-d3['# Good']\n",
    "    d3['% Good'] = round(d3['# Good']/d3['# Good'].sum()*100,1)\n",
    "    d3['% Bad'] = round(d3['# Bad']/d3['# Bad'].sum()*100,1)\n",
    "    d3['# Total']=d2['Y'].count()\n",
    "    d3['% Total'] = round(d3['# Total']/d3['# Total'].sum()*100,1)\n",
    "\n",
    "    d3['Information Odds'] = round(d3['% Good'] / d3['% Bad'],2)\n",
    "    d3['Bad Rate'] = round(d3['# Bad']/(d3['# Bad']+d3['# Good'])*100,2)\n",
    "   \n",
    "    d3['WoE'] = round(np.log(d3['% Good']/d3['% Bad']),2)\n",
    "    #print(d3)\n",
    "    iv = ((d3['% Good']-d3['% Bad'])*d3['WoE']/100)\n",
    "    d4=d3.sort_index()\n",
    "    d4 = d3.drop(columns=['min'], axis=1)\n",
    "    woe = list(d3['WoE'].values)\n",
    "   \n",
    "    return d4,iv,woe    \n",
    "\n",
    "def replace_woe(series,cut,woe):\n",
    "    list=[]\n",
    "    i=0\n",
    "    while i<len(series):\n",
    "        valuek=series[i]\n",
    "        j=len(cut)-2\n",
    "        m=len(cut)-2\n",
    "        while j>=0:\n",
    "            if valuek>cut[j]:\n",
    "                j=-1\n",
    "            else:\n",
    "                j -=1\n",
    "                m -= 1\n",
    "        list.append(woe[m])\n",
    "        i += 1\n",
    "    return list\n",
    "   \n",
    "   \n",
    "def replace_woe_str(series,cut,woe):\n",
    "    list=[]\n",
    "    i=0\n",
    "    while i<len(series):\n",
    "        valuek=series[i]\n",
    "        #print(valuek)\n",
    "        index = cut.index(valuek)\n",
    "        #print(index)\n",
    "        list.append(woe[index])\n",
    "        #print(list.append(woe[index]))\n",
    "        i += 1\n",
    "    return list\n",
    "\n",
    "d = pd.DataFrame(index = [0],columns=['Characteristics','Information Value'])\n",
    "d.to_csv(charsAnalsysis+'dd.csv')        \n",
    "\n",
    "if runWoEAnalysis:\n",
    "    print(\"#################################################################\")\n",
    "    print(\"#                                                               #\")\n",
    "    print(\"#                     WOE ANALYSIS                              #\")\n",
    "    print(\"#                                                               #\")\n",
    "    print(\"#################################################################\")\n",
    "   \n",
    "    print(\"\")\n",
    "    print(\"Start WOE Analysis.....\")\n",
    "    print(\"\")\n",
    "   \n",
    "   \n",
    "    loc = inputData  \n",
    "    d= pd.read_csv(loc+fileName)#, index_col=0\n",
    "    d = d.loc[(d['Target'] < 2)]\n",
    "   \n",
    "    print(d.Target.value_counts(dropna=False))\n",
    "   \n",
    "   \n",
    "    woeList = []\n",
    "    cutList = []\n",
    "    for z in range(len(chars)):\n",
    "   \n",
    "        #print(d[chars[z]])\n",
    "        if(d[chars[z]].dtype !='object'):\n",
    "           \n",
    "           \n",
    "            print(\"WOE analysis for this char: \",chars[z])\n",
    "            loc = inputData\n",
    "           \n",
    "            df= pd.read_csv(loc+fileName)#, index_col=0\n",
    "            #df = df.drop(columns=['Unnamed: 0'],axis=1)\n",
    "\n",
    "            cutx3 = binners[z]\n",
    "            #print(binners[z])\n",
    "            dfx3, ivx3, woex3 = self_bin(df['Target'],df[chars[z]], cutx3)\n",
    "            dfx3 = dfx3.reset_index()\n",
    "       \n",
    "               \n",
    "           \n",
    "           \n",
    "            dfx3.to_csv(loc+'dfx3.csv')  \n",
    "           \n",
    "           \n",
    "            a = pd.read_csv(charsAnalsysis+'dd.csv',index_col=0)\n",
    "            dd = pd.DataFrame({'Characteristics':chars[z],'Information Value':\"%.3f\" %round(ivx3.sum(),3)}, index=[0])\n",
    "            s = pd.concat([a, dd])\n",
    "            s = s.dropna()\n",
    "            s.to_csv(charsAnalsysis+'dd.csv')\n",
    "           \n",
    "           \n",
    "            df = pd.read_csv(loc+'dfx3.csv')#, index_col=0\n",
    "            df = df.drop(columns=['Unnamed: 0'],axis=1)\n",
    "            df.loc['Total', '# Bad']= df['# Bad'].sum(axis=0)\n",
    "            df.loc['Total', '# Good']= df['# Good'].sum(axis=0)\n",
    "            df.loc['Total', '# Total']= df['# Total'].sum(axis=0)\n",
    "            df.loc['Total', '% Total']= round(df['% Total'].sum(axis=0))\n",
    "            df.loc['Total', '% Bad']= round(df['% Bad'].sum(axis=0))\n",
    "            df.loc['Total', '% Good']= round(df['% Good'].sum(axis=0))\n",
    "           \n",
    "           \n",
    "            df.iloc[len(df)-1, df.columns.get_loc(chars[z])] = 'Total'\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('Information Odds')] =\"%.2f\" % round(df['# Good'].sum() / (df['# Bad'].sum()),2)\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('Bad Rate')] = \"%.2f\" %round(df['# Bad'].sum()*100 / (df['# Good'].sum() + df['# Bad'].sum()),1)\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('WoE')] = ''\n",
    "           \n",
    "           \n",
    "            df['# Bad'] = df['# Bad'].apply(lambda x : \"{:,}\".format(x))\n",
    "            df['# Good'] = df['# Good'].apply(lambda x : \"{:,}\".format(x))\n",
    "            df['# Total'] = df['# Total'].apply(lambda x : \"{:,}\".format(x))\n",
    "            df.loc[''] = ''                                                                      \n",
    "            df.loc['Inf. Value'] = 'Inf. Value:'                                                                      \n",
    "           \n",
    "            df.iloc[len(df)-1, df.columns.get_loc(chars[z])] = 'Inf. Value: '\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('# Bad')] = ''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('# Good')] = \"%.3f\" %round(ivx3.sum(),3)\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('# Total')] = ''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('% Total')] = ''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('% Bad')] =''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('% Good')] = ''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('Information Odds')] = ''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('Bad Rate')] = ''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('WoE')] = ''\n",
    "           \n",
    "           \n",
    "            def render_mpl_table(data, col_width=3.0, row_height=0.625, font_size=14.5,\n",
    "                                 header_color='#33B3FF', row_colors=['#f1f1f2', 'w'], edge_color='w',\n",
    "                                 bbox=[0, 0, 1, 1], header_columns=0,\n",
    "                                 ax=None, **kwargs):\n",
    "                if ax is None:\n",
    "                    size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "                    fig, ax = plt.subplots(figsize=size)\n",
    "                    ax.axis('off')\n",
    "                mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n",
    "                mpl_table.auto_set_font_size(False)\n",
    "                mpl_table.set_fontsize(font_size)\n",
    "           \n",
    "                for k, cell in mpl_table._cells.items():\n",
    "                    cell.set_edgecolor(edge_color)\n",
    "                    if k[0] == 0 or k[1] < header_columns:\n",
    "                        cell.set_text_props(weight='bold', color='w')\n",
    "                        cell.set_facecolor(header_color)\n",
    "                    else:\n",
    "                        cell.set_facecolor(row_colors[k[0]%len(row_colors) ])\n",
    "                return ax.get_figure(), ax\n",
    "           \n",
    "            woeList.append(woex3)\n",
    "            cutList.append(cutx3)\n",
    "           \n",
    "        else:\n",
    "            loc = inputData\n",
    "           \n",
    "            print(\"WOE analysis for this char: \",chars[z])\n",
    "            df= pd.read_csv(loc+fileName)\n",
    "            #df = df.drop(columns=['Unnamed: 0'],axis=1)\n",
    "            #df[chars[z]] = df[chars[z]].fillna('Missing')\n",
    "            #binners[z]\n",
    "            df[chars[z]+'_bin'] = (\n",
    "                    df[chars[z]]\n",
    "                    .apply(lambda x: [k for k in binners[z].keys() if x in binners[z][k]])\n",
    "                    .str[0])\n",
    "                   \n",
    "\n",
    "            dfx3, ivx3, woex3 = self_bin_char(df['Target'],df[chars[z]+'_bin'])\n",
    "            dfx3 = dfx3.reset_index()\n",
    "            cutx3 = list((dfx3[chars[z]]))\n",
    "               \n",
    " \n",
    "           \n",
    "            dfx3.to_csv(loc+'dfx3.csv')  \n",
    "            #print(chars[z]+\" - IV: \",round(ivx3.sum(),3))\n",
    "           \n",
    "            a = pd.read_csv(charsAnalsysis+'dd.csv',index_col=0)\n",
    "            dd = pd.DataFrame({'Characteristics':chars[z],'Information Value':\"%.3f\" %round(ivx3.sum(),3)}, index=[0])\n",
    "            s = pd.concat([a, dd])\n",
    "            s = s.dropna()\n",
    "            s.to_csv(charsAnalsysis+'dd.csv')\n",
    "           \n",
    "           \n",
    "            df = pd.read_csv(loc+'dfx3.csv', index_col=0)\n",
    "           \n",
    "            df.loc['Total', '# Bad']= df['# Bad'].sum(axis=0)\n",
    "            df.loc['Total', '# Good']= df['# Good'].sum(axis=0)\n",
    "            df.loc['Total', '# Total']= df['# Total'].sum(axis=0)\n",
    "            df.loc['Total', '% Total']= round(df['% Total'].sum(axis=0))\n",
    "            df.loc['Total', '% Bad']= round(df['% Bad'].sum(axis=0))\n",
    "            df.loc['Total', '% Good']= round(df['% Good'].sum(axis=0))\n",
    "           \n",
    "           \n",
    "            df.iloc[len(df)-1, df.columns.get_loc(chars[z])] = 'Total'\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('Information Odds')] =\"%.2f\" % round(df['# Good'].sum() / (df['# Bad'].sum()),2)\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('Bad Rate')] = \"%.2f\" %round(df['# Bad'].sum()*100 / (df['# Good'].sum() + df['# Bad'].sum()),1)\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('WoE')] = ''\n",
    "           \n",
    "           \n",
    "            df['# Bad'] = df['# Bad'].apply(lambda x : \"{:,}\".format(x))\n",
    "            df['# Good'] = df['# Good'].apply(lambda x : \"{:,}\".format(x))\n",
    "            df['# Total'] = df['# Total'].apply(lambda x : \"{:,}\".format(x))\n",
    "            df.loc[''] = ''                                                                      \n",
    "            df.loc['Information Value'] = 'Inf. Value:'                                                                      \n",
    "           \n",
    "            df.iloc[len(df)-1, df.columns.get_loc(chars[z])] = 'Information Value: '\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('# Bad')] = ''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('# Good')] = \"%.3f\" %round(ivx3.sum(),3)\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('# Total')] = ''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('% Total')] = ''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('% Bad')] =''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('% Good')] = ''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('Information Odds')] = ''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('Bad Rate')] = ''\n",
    "            df.iloc[len(df)-1, df.columns.get_loc('WoE')] = ''\n",
    "           \n",
    "           \n",
    "            def render_mpl_table(data, col_width=3.0, row_height=0.625, font_size=14.5,\n",
    "                                 header_color='#33B3FF', row_colors=['#f1f1f2', 'w'], edge_color='w',\n",
    "                                 bbox=[0, 0, 1, 1], header_columns=0,\n",
    "                                 ax=None, **kwargs):\n",
    "                if ax is None:\n",
    "                    size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "                    fig, ax = plt.subplots(figsize=size)\n",
    "                    ax.axis('off')\n",
    "                mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n",
    "                mpl_table.auto_set_font_size(False)\n",
    "                mpl_table.set_fontsize(font_size)\n",
    "           \n",
    "                for k, cell in mpl_table._cells.items():\n",
    "                    cell.set_edgecolor(edge_color)\n",
    "                    if k[0] == 0 or k[1] < header_columns:\n",
    "                        cell.set_text_props(weight='bold', color='w')\n",
    "                        cell.set_facecolor(header_color)\n",
    "                    else:\n",
    "                        cell.set_facecolor(row_colors[k[0]%len(row_colors) ])\n",
    "                return ax.get_figure(), ax\n",
    "           \n",
    "   \n",
    "            woeList.append(woex3)\n",
    "            cutList.append(cutx3)\n",
    "       \n",
    "\n",
    "           \n",
    "        fig,ax = render_mpl_table(df, header_columns=0, col_width=2)\n",
    "        fig.savefig(charsAnalsysis+chars[z]+\"_WOE.png\")\n",
    "        df.to_csv(charsAnalsysis+chars[z]+'_WOE.csv')      \n",
    "    print(\"\")\n",
    "    print(\" WOE Analysis Completed!\")\n",
    "    print(\"\")\n",
    "\n",
    "     \n",
    "       \n",
    "     \n",
    "       \n",
    "     \n",
    "       \n",
    "if replaceWoe:    \n",
    "   \n",
    "    print(\"#################################################################\")\n",
    "    print(\"#                                                               #\")\n",
    "    print(\"#              REPLACE WOE                                      #\")\n",
    "    print(\"#                                                               #\")\n",
    "    print(\"#################################################################\")\n",
    "   \n",
    "    loc = inputData\n",
    "    data = pd.read_csv(loc+fileName)\n",
    "\n",
    "   \n",
    "    print(\"\")\n",
    "    print(\"Start Replacing WOE in the input datset.....\")\n",
    "    print(\"\")\n",
    "\n",
    "   \n",
    "    for z in range(len(chars)):\n",
    "       \n",
    "        print(\"Replace chars Value with WoE: \",chars[z])\n",
    "        if(data[chars[z]].dtype !='object'):\n",
    "            data[chars[z]] = Series(replace_woe(data[chars[z]], cutList[z], woeList[z]))\n",
    "        else:\n",
    "            data[chars[z]] = data[chars[z]].fillna('Missing')\n",
    "            data[chars[z]+'_bin'] = (\n",
    "                    data[chars[z]]\n",
    "                    .apply(lambda x: [k for k in binners[z].keys() if x in binners[z][k]])\n",
    "                    .str[0])\n",
    "                       \n",
    "            data[chars[z]] = Series(replace_woe_str(data[chars[z]+\"_bin\"], cutList[z], woeList[z]))\n",
    "    print(\"Replace chars value with WoE: completed .....\")\n",
    "    data.to_csv(loc+'train_for_development_WOE.csv')\n",
    "\n",
    "    d = pd.read_csv(charsAnalsysis+'dd.csv')\n",
    "    d = d.sort_values(by=['Information Value'], ascending=False)\n",
    "    d = d.drop(columns=['Unnamed: 0'],axis=1)\n",
    "    fig,ax = render_iv_table(d, header_columns=0, col_width=7, fontsize = 15)\n",
    "    fig.savefig(charsAnalsysis+\"_FeaturesInformationValue.png\")#,  \n",
    "    print(\"\")\n",
    "    print(\"Replacing WOE compelted!\")\n",
    "    print(\"\")\n",
    "   \n",
    "   \n",
    "if correlationsAnalysis:\n",
    "    print(\"#################################################################\")\n",
    "    print(\"#                                                               #\")\n",
    "    print(\"#              CORRELATION ANALYSIS                             #\")\n",
    "    print(\"#                                                               #\")\n",
    "    print(\"#################################################################\")\n",
    "   \n",
    "    print(\"\")\n",
    "    print(\"Start correlation analysis..\")\n",
    "    data = pd.read_csv(loc+'train_for_development_WOE.csv',index_col=0)\n",
    "    data = data[chars]\n",
    "    corr=data.corr()\n",
    "    corr.to_csv(charsAnalsysis+'correlationAnalysisReport.csv')\n",
    "    xticks = [col_list]\n",
    "    fig=plt.figure()\n",
    "    fig.set_size_inches(30,30)\n",
    "    ax1=fig.add_subplot(1,1,1)\n",
    "    sns.heatmap(corr,vmin=-1, vmax=1 ,cmap='hsv', annot=True, square=True)\n",
    "    #ax1.set_xticklabels(xticks,rotation= 0, fontsize = 22)\n",
    "    #plt.xticks(ticks=X_Tick_List,labels=X_Tick_LabeL_List, rotation=25,fontsize=8)\n",
    "   \n",
    "    plt.show()    \n",
    "    print(\"\")\n",
    "    print(\"Correlation analysis completed!\")\n",
    "    print(\"\")\n",
    "   \n",
    "if trainModel:\n",
    "\n",
    "\n",
    "    print(\"#################################################################\")\n",
    "    print(\"#                                                               #\")\n",
    "    print(\"#                       TRAIN MODEL                             #\")\n",
    "    print(\"#                                                               #\")\n",
    "    print(\"#################################################################\")\n",
    "   \n",
    "    data = pd.read_csv(loc+'train_for_development_WOE.csv',index_col=0)\n",
    "   \n",
    "   \n",
    "    data = data[['Target','grade','emp_length','dti','Orig_FicoScore','inq_last_6mths','acc_open_past_24mths','mort_acc','mths_since_recent_bc','num_rev_tl_bal_gt_0','percent_bc_gt_75']]\n",
    "   \n",
    "   \n",
    "       \n",
    "   \n",
    "   \n",
    "    Y=data['Target']\n",
    "    X=data[col_list]\n",
    "   \n",
    "   \n",
    "    X1=sm.add_constant(X)\n",
    "       \n",
    "    logit=sm.Logit(Y,X1)\n",
    "    result=logit.fit()\n",
    "    print(result.summary())\n",
    "   \n",
    "    plt.rcParams['font.sans-serif'] = ['FangSong']        # Specify default font\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    Y_test=data['Target']\n",
    "    X_test=data[col_list]\n",
    "   \n",
    "    X2=sm.add_constant(X_test)\n",
    "    resu=result.predict(X2)\n",
    "    fpr,tpr,threshold=roc_curve(Y_test,resu)\n",
    "    rocauc=auc(fpr,tpr)*100\n",
    "    x = round((rocauc-50)*2,1)\n",
    "   \n",
    "   \n",
    "   \n",
    "    print(\"                 \")\n",
    "    print(\"Train Gini:  \",x)\n",
    "   \n",
    "    print(\"                 \")\n",
    "   \n",
    "   \n",
    "   \n",
    "    fig = plt.figure()    \n",
    "    fig.suptitle('Train Sample TOC')\n",
    "    ax1 = fig.add_subplot(1,1,1)\n",
    "    plt.plot(fpr,tpr,'b',label='ROC: %0.1f'% rocauc)\n",
    "    plt.plot(fpr,tpr,'b',label='Gini: %0.1f'% x)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlabel('% Cumulative Good')\n",
    "    plt.ylabel('% Cumulative Bad')\n",
    "    plt.savefig(modelDevelopment+'_TrainSample_TOC.png')\n",
    "    plt.show()\n",
    "   \n",
    " \n",
    "   \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn2pmml import sklearn2pmml\n",
    "    from sklearn2pmml.pipeline import PMMLPipeline\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    logreg = LogisticRegression()\n",
    "    # set up a pmml pipeline to fit the model\n",
    "    pipeline = PMMLPipeline([\n",
    "        (\"classifier\", LogisticRegression())\n",
    "    ])\n",
    "    pipeline.fit(X2, Y)\n",
    "\n",
    "    # save the pmml model to disk\n",
    "\n",
    "    sklearn2pmml(pipeline, \"LogisticRegression_model.pmml\", with_repr = True)\n",
    "# =============================================================================\n",
    "#     import shap\n",
    "#     import sklearn\n",
    "#\n",
    "#     model = sklearn.linear_model.LogisticRegression(penalty=\"l2\", C=0.1)\n",
    "#     model.fit(X2, Y_test)\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "#     LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
    "#               intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "#               penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
    "#               verbose=0, warm_start=False)\n",
    "# =============================================================================\n",
    "\n",
    "    explainer = shap.LinearExplainer(model, X2, feature_dependence=\"independent\")\n",
    "   \n",
    "       \n",
    "   \n",
    "    #sklearn2pmml(pipeline, \"MyArchivedLogRegModel.pmml\")\n",
    "   \n",
    "    Pkl_Filename = modelDevelopment+\"Trained_Model.pkl\"  \n",
    "   \n",
    "    with open(Pkl_Filename, 'wb') as file:  \n",
    "        pickle.dump(logit, file)\n",
    "   \n",
    "   \n",
    "    data['Probability'] = resu\n",
    "    def Prediction(row):\n",
    "        if(row['Probability'] >= 0.50):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    data['Prediction'] = data.apply(Prediction, axis=1)\n",
    "   \n",
    "    print(\"Average probabiliyt of being Good: \",str(round(data['Probability'].mean()*100,1)))  \n",
    "    data.to_csv(loc+'input.csv')        \n",
    "    x = pd.crosstab(data['Probability'],data['Target'])        \n",
    "    x.to_csv(loc+'scoreDistribution.csv')\n",
    "    data = data['Probability']\n",
    "    data = data.reset_index()\n",
    "   \n",
    "   \n",
    "    d = pd.read_csv(loc+'train_for_development_WOE.csv', index_col=0)\n",
    "    d = d.reset_index()\n",
    "   \n",
    "   \n",
    "    df = d.merge(data, left_index=True, right_index=True)\n",
    "   \n",
    "   \n",
    "    df = df.drop(columns=['index_x','index_y'], axis=1)\n",
    "   \n",
    "    df.to_csv(modelDevelopment+'MIV.csv')\n",
    "   \n",
    "   \n",
    "    print(\"\")\n",
    "    print(\"Training Model: completed !\")\n",
    "    print(\"\")\n",
    "\n",
    "   \n",
    "if MIV:\n",
    "    print(\"#################################################################\")\n",
    "    print(\"#                                                               #\")\n",
    "    print(\"#                         MIV ANALYSIS                          #\")\n",
    "    print(\"#                                                               #\")\n",
    "    print(\"#################################################################\")\n",
    "   \n",
    "    d = pd.DataFrame(index = [0],columns=['Characteristics','MIV'])\n",
    "    d.to_csv(loc+'ee.csv')  \n",
    "   \n",
    "   \n",
    "    d= pd.read_csv(modelDevelopment+'MIV.csv')#, index_col=0\n",
    "    d = d.drop(columns=['Unnamed: 0'],axis=1)\n",
    "   \n",
    "   \n",
    "   \n",
    "    for z in range(len(chars)):\n",
    "        if(chars[z] not in col_list):\n",
    "            d= pd.read_csv(modelDevelopment+'MIV.csv')#, index_col=0\n",
    "            d = d.drop(columns=['Unnamed: 0'],axis=1)\n",
    "            if(d[chars[z]].dtype !='object'):    \n",
    "                df= pd.read_csv(modelDevelopment+'MIV.csv')#, index_col=0\n",
    "                df = df.drop(columns=['Unnamed: 0'],axis=1)\n",
    "               \n",
    "                df[chars[z]+'_bin'] = pd.cut(x=df[chars[z]], bins=binners[z])\n",
    "                col = ['prob',chars[z]+'_bin']\n",
    "                df = df[col]\n",
    "                dfx3 = df.groupby(chars[z]+'_bin').mean()\n",
    "                dfx3 = dfx3.reset_index()\n",
    "                dfx3 = dfx3.drop(columns=[chars[z]+'_bin'],axis=1)\n",
    "                d = pd.read_csv(charsAnalsysis+chars[z]+'.csv')\n",
    "                d = d[:-3]\n",
    "                data = d.merge(dfx3, left_index=True, right_index=True)\n",
    "                data = data.drop(columns=['Unnamed: 0'],axis=1)    \n",
    "                eg = []\n",
    "               \n",
    "                words = np.array(data['# Total'])\n",
    "                #print(words)\n",
    "                d = []\n",
    "                for string in words:\n",
    "                    #d.append(0)\n",
    "                    newString = str(string).replace(',','')\n",
    "                   \n",
    "                    d.append(newString)\n",
    "                   \n",
    "                data['t'] =d\n",
    "                #a = data['t'].astype(float)\n",
    "                t = np.array(data['t'].astype(float))\n",
    "                p = np.array(data['prob'])\n",
    "                for n in range(len(t)):\n",
    "                    eg.append(0)\n",
    "                    eg[n] = round(float(t[n])*p[n],1)\n",
    "                data['exp_Goods'] = eg\n",
    " \n",
    "               \n",
    "                eb = []\n",
    "               \n",
    "                p = np.array(data['prob'])\n",
    "                for n in range(len(t)):\n",
    "                    eb.append(0)\n",
    "                    eb[n] = round(float(t[n])*(1-p[n]),1)\n",
    "                data['exp_Bads'] = eb\n",
    "               \n",
    "                data = data.drop(columns=['t'],axis=1)\n",
    "                data['exp_pct_Goods'] = round(data['exp_Goods']/data['exp_Goods'].sum()*100,1)\n",
    "                data['exp_pct_Bads'] = round(data['exp_Bads']/data['exp_Bads'].sum()*100,1)\n",
    "                data['exp_WoE'] = round(np.log(data['exp_pct_Goods']/data['exp_pct_Bads']),2)          \n",
    "                data['DeltaScore'] = data['WoE'] - data['exp_WoE']\n",
    "\n",
    "                data['MIV'] = data['DeltaScore']*data['% Good'] - data['DeltaScore']*data['% Bad']\n",
    "                x = round(data['MIV'].sum(),2)\n",
    "                data.to_csv(loc+chars[z]+'delta.csv')\n",
    "               #print(chars[z]+': '+str(x))\n",
    "                a = pd.read_csv(loc+'ee.csv',index_col=0)\n",
    "                dd = pd.DataFrame({'Characteristics':chars[z],'MIV':\"%.3f\" %round(x,2)}, index=[0])\n",
    "                s = pd.concat([a, dd])\n",
    "                s = s.dropna()\n",
    "                s.to_csv(loc+'ee.csv')            \n",
    "               \n",
    "               \n",
    "               \n",
    "            else:\n",
    "                df= pd.read_csv(modelDevelopment+'MIV.csv')#, index_col=0\n",
    "                df = df.drop(columns=['Unnamed: 0'],axis=1)\n",
    "                df[chars[z]+'_bin'] = df[chars[z]]\n",
    "                col = ['prob',chars[z]+'_bin']\n",
    "                df = df[col]\n",
    "                dfx3 = df.groupby(chars[z]+'_bin').mean()\n",
    "                dfx3 = dfx3.reset_index()\n",
    "                dfx3 = dfx3.drop(columns=[chars[z]+'_bin'],axis=1)\n",
    "                d = pd.read_csv(charsAnalsysis+chars[z]+'.csv')\n",
    "                d = d[:-3]\n",
    "                data = d.merge(dfx3, left_index=True, right_index=True)\n",
    "                data = data.drop(columns=['Unnamed: 0'],axis=1)    \n",
    "                eg = []\n",
    "               \n",
    "                words = np.array(data['# Total'])\n",
    "                d = []\n",
    "                for string in words:\n",
    "                    #d.append(0)\n",
    "                    newString = str(string).replace(',','')\n",
    "                    d.append(newString)\n",
    "                   \n",
    "                data['t'] =d\n",
    "                #a = data['t'].astype(float)\n",
    "                t = np.array(data['t'].astype(float))\n",
    "                p = np.array(data['prob'])\n",
    "                for n in range(len(t)):\n",
    "                    eg.append(0)\n",
    "                    eg[n] = round(float(t[n])*p[n],1)\n",
    "                data['exp_Goods'] = eg\n",
    "\n",
    "                eb = []\n",
    "               \n",
    "                p = np.array(data['prob'])\n",
    "                for n in range(len(t)):\n",
    "                    eb.append(0)\n",
    "                    eb[n] = round(float(t[n])*(1-p[n]),1)\n",
    "                data['exp_Bads'] = eb\n",
    "               \n",
    "                data = data.drop(columns=['t'],axis=1)\n",
    "                data['exp_pct_Goods'] = round(data['exp_Goods']/data['exp_Goods'].sum()*100,1)\n",
    "                data['exp_pct_Bads'] = round(data['exp_Bads']/data['exp_Bads'].sum()*100,1)\n",
    "                data['exp_WoE'] = round(np.log(data['exp_pct_Goods']/data['exp_pct_Bads']),2)          \n",
    "                data['DeltaScore'] = data['WoE'] - data['exp_WoE']\n",
    "\n",
    "                data['MIV'] = data['DeltaScore']*data['% Good'] - data['DeltaScore']*data['% Bad']\n",
    "                x = round(data['MIV'].sum(),2)\n",
    "                data.to_csv(loc+chars[z]+'delta.csv')\n",
    "                #print(chars[z]+': '+str(x))      \n",
    "                a = pd.read_csv(loc+'ee.csv',index_col=0)\n",
    "                dd = pd.DataFrame({'Characteristics':chars[z],'MIV':\"%.3f\" %round(x,2)}, index=[0])\n",
    "                s = pd.concat([a, dd])\n",
    "                s = s.dropna()\n",
    "                s.to_csv(loc+'ee.csv')                  \n",
    "    d = pd.read_csv(loc+'ee.csv')\n",
    "    d = d.sort_values(by=['MIV'], ascending=False)\n",
    "    d = d.drop(columns=['Unnamed: 0'],axis=1)\n",
    "    fig,ax = render_iv_table(d, header_columns=0, col_width=7, fontsize = 15)\n",
    "    fig.savefig(\"MIV_.png\")#,\n",
    "\n",
    "   \n",
    "   \n",
    "if scaleModel:\n",
    "   \n",
    "# =============================================================================\n",
    "#         #################################################################################\n",
    "#    \n",
    "#         #        CHANGE THIS PART\n",
    "#        \n",
    "#         ################################################################################\n",
    "#    \n",
    "#    \n",
    "#         print(\"#################################################################\")\n",
    "#         print(\"#                                                               #\")\n",
    "#         print(\"#                   SCALE THE MODEL                             #\")\n",
    "#         print(\"#                                                               #\")\n",
    "#         print(\"# Score: 660                                                    #\")\n",
    "#         print(\"# Odds: 15:1                                                    #\")\n",
    "#         print(\"# PDO: 40                                                       #\")\n",
    "#         print(\"#                                                               #\")\n",
    "#         print(\"#################################################################\")\n",
    "#    \n",
    "#     # =============================================================================\n",
    "#     #\n",
    "# # =============================================================================\n",
    "# # ========================================================================================\n",
    "# #                            coef    std err          z      P>|z|      [0.025      0.975]\n",
    "# # ----------------------------------------------------------------------------------------\n",
    "# # const                    1.6079      0.004    387.797      0.000       1.600       1.616\n",
    "# # grade                    0.9010      0.008    111.523      0.000       0.885       0.917\n",
    "# # emp_length               0.9479      0.046     20.427      0.000       0.857       1.039\n",
    "# # dti                      0.5118      0.019     26.629      0.000       0.474       0.549\n",
    "# # Orig_FicoScore           0.0794      0.016      5.075      0.000       0.049       0.110\n",
    "# # inq_last_6mths           0.2056      0.027      7.723      0.000       0.153       0.258\n",
    "# # acc_open_past_24mths     0.4851      0.020     24.016      0.000       0.445       0.525\n",
    "# # mort_acc                 0.6678      0.029     23.427      0.000       0.612       0.724\n",
    "# # mths_since_recent_bc     0.1967      0.032      6.185      0.000       0.134       0.259\n",
    "# # num_rev_tl_bal_gt_0      0.1295      0.030      4.274      0.000       0.070       0.189\n",
    "# # percent_bc_gt_75         0.0459      0.026      1.766      0.077      -0.005       0.097\n",
    "# # ========================================================================================\n",
    "# # =============================================================================\n",
    "#\n",
    "#    \n",
    "#    \n",
    "#    \n",
    "#         coe = [1.6079,0.9010,0.9479,0.5118,0.0794,0.2056,0.4851,0.6678,0.1967,0.1295,0.0459] # List of features coefficients\n",
    "#    \n",
    "#         import math\n",
    "#        \n",
    "#         score = 660\n",
    "#         odds = 15\n",
    "#         pdo = 40\n",
    "#        \n",
    "#         Factor = pdo/math.log(2)\n",
    "#         Offset = score - (Factor*math.log(15))\n",
    "#         print(\"\")\n",
    "#         print(\"Scaling Factor: \",str(Factor))\n",
    "#         print(\"Scaling Offest: \",str(Offset))\n",
    "#         print(\"\")\n",
    "#         data = pd.read_csv(loc+'development.csv')# input data without WOE values\n",
    "#        # data = data.drop(columns=['Unnamed: 0'],axis=1)\n",
    "#    \n",
    "#         for z in range(len(chars)):\n",
    "#            \n",
    "#    \n",
    "#             if(data[chars[z]].dtype !='object'):\n",
    "#                 data[chars[z]] = Series(replace_woe(data[chars[z]], cutList[z], woeList[z]))\n",
    "#             else:\n",
    "#                 data[chars[z]+'_bin'] = (\n",
    "#                         data[chars[z]]\n",
    "#                         .apply(lambda x: [k for k in binners[z].keys() if x in binners[z][k]])\n",
    "#                         .str[0])\n",
    "#                 data[chars[z]] = Series(replace_woe_str(data[chars[z]+\"_bin\"], cutList[z], woeList[z]))\n",
    "#    \n",
    "#         data.to_csv(loc+'developmentDataset_with_WOE.csv')\n",
    "#        \n",
    "#         data['x1']  = round((data['grade']*coe[1]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "#         data['x2']  = round((data['emp_length']*coe[2]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "#         data['x3']  = round((data['dti']*coe[3]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "#         data['x4']  = round((data['Orig_FicoScore']*coe[4]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "#         data['x5']  = round((data['inq_last_6mths']*coe[5]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "#         data['x6']  = round((data['acc_open_past_24mths']*coe[6]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "#         data['x7']  = round((data['mort_acc']*coe[7]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "#         data['x8']  = round((data['mths_since_recent_bc']*coe[8]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "#         data['x9']  = round((data['num_rev_tl_bal_gt_0']*coe[9]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "#         data['x10'] = round((data['percent_bc_gt_75']*coe[10]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "#    \n",
    "#         data['Score'] = data['x1']+    data['x2']+    data['x3']+    data['x4']+    data['x5']+    data['x6']+    data['x7']+data['x8']+data['x9']+data['x10']\n",
    "#         #print(data)\n",
    "#         data.to_csv(loc+'_development_scored_data.csv')\n",
    "#         print(\"\")\n",
    "#         print(\"Average Score of Population: \", str(round(data['Score'].mean(),1)))\n",
    "#         g = data.loc[data['Target'] == 1]\n",
    "#         print(\"Average Score of Goods: \", str(round(g['Score'].mean(),1)))\n",
    "#         g = data.loc[data['Target'] == 0]\n",
    "#         print(\"Average Score of Bads: \", str(g['Score'].mean()))\n",
    "#         g = data.loc[data['Target'] == -1]\n",
    "#         print(\"Average Score of Indeterminates: \", str(round(g['Score'].mean(),1)))\n",
    "#    \n",
    "#         print(\"\")\n",
    "#         print(\"Minimum Score: \",str(data['Score'].min()))\n",
    "#         print(\"Average Score: \",str(data['Score'].mean()))\n",
    "#         print(\"Maximum Score: \",str(data['Score'].max()))\n",
    "#         print(\"\")\n",
    "#    \n",
    "#         data['ScoreBinned']=pd.cut(data['Score'], bins=[0,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,800,900])\n",
    "#         x = pd.crosstab(data['ScoreBinned'],data['Target'])        \n",
    "#        \n",
    "#         x.to_csv(modelDevelopment+'Development_scaledScoreDistribution.csv')\n",
    "#         print(\"The scaled score distribution has been saved here: \",modelDevelopment+'scaledScoreDistribution.csv')\n",
    "#         print(\"\")\n",
    "#         print(\"Development Scaling completed!\")\n",
    "# =============================================================================\n",
    "   \n",
    "        print(\"#################################################################\")\n",
    "        print(\"#                                                               #\")\n",
    "        print(\"#                   EVALUATE 2015                               #\")\n",
    "        print(\"#                                                               #\")\n",
    "        print(\"#################################################################\")  \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "        data = pd.read_csv(loc+'2015.csv')# input data without WOE values\n",
    "        #data = data.drop(columns=['Unnamed: 0'],axis=1)\n",
    "        data = data[['Target','grade','emp_length','dti','Orig_FicoScore','inq_last_6mths','acc_open_past_24mths','mort_acc','mths_since_recent_bc','num_rev_tl_bal_gt_0','percent_bc_gt_75']]\n",
    "        for z in range(len(chars)):\n",
    "   \n",
    "            if(data[chars[z]].dtype !='object'):\n",
    "                data[chars[z]] = Series(replace_woe(data[chars[z]], cutList[z], woeList[z]))\n",
    "            else:\n",
    "                data[chars[z]+'_bin'] = (\n",
    "                        data[chars[z]]\n",
    "                        .apply(lambda x: [k for k in binners[z].keys() if x in binners[z][k]])\n",
    "                        .str[0])\n",
    "                data[chars[z]] = Series(replace_woe_str(data[chars[z]+\"_bin\"], cutList[z], woeList[z]))\n",
    "   \n",
    "        Y_test=data['Target']\n",
    "        X_test=data[col_list]\n",
    "       \n",
    "       \n",
    "        #model = pickle.load(open(modelDevelopment+\"Trained_Model.pkl\", 'rb'))\n",
    "       \n",
    "       \n",
    "        X2=sm.add_constant(X_test)\n",
    "        resu=result.predict(X2)\n",
    "        fpr,tpr,threshold=roc_curve(Y_test,resu)\n",
    "        rocauc=auc(fpr,tpr)*100\n",
    "        x = round((rocauc-50)*2,1)\n",
    "       \n",
    "       \n",
    "       \n",
    "        print(\"                 \")\n",
    "        print(\"Generalisation Gini:  \",x)\n",
    "       \n",
    "        print(\"                 \")\n",
    "           \n",
    "        data['Probability'] = resu\n",
    "   \n",
    "        def Prediction(row):\n",
    "            if(row['Probability'] > 0.50):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "       \n",
    "        data['Prediction'] = data.apply(Prediction, axis=1)\n",
    "       \n",
    "        #data.to_csv(loc+'va')\n",
    "# =============================================================================\n",
    "#         shap_values = explainer.shap_values(X2)\n",
    "#         shap.summary_plot(shap_values, X2)\n",
    "#\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "#         print(\"Import pmml\")\n",
    "#         from pypmml import Model\n",
    "#\n",
    "#         model = Model.fromFile(\"LogisticRegression_model.pmml\")\n",
    "#        \n",
    "#         resu=model.predict(X2)\n",
    "#         fpr,tpr,threshold=roc_curve(Y_test,resu)\n",
    "#         rocauc=auc(fpr,tpr)*100\n",
    "#         x = round((rocauc-50)*2,1)\n",
    "#        \n",
    "#        \n",
    "#        \n",
    "#         print(\"                 \")\n",
    "#         print(\"Generalisation Gini pmml:  \",x)\n",
    "#        \n",
    "#         print(\"                 \")\n",
    "# =============================================================================\n",
    "\n",
    "if False:        \n",
    "       \n",
    "        from sklearn.metrics import f1_score\n",
    "       \n",
    "        actual = np.array(data['Target'])\n",
    "        pred = np.array(data['Prediction'])\n",
    "        print(\"F1 Score: \",str(f1_score(actual, pred)))\n",
    "\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "\n",
    "        print(confusion_matrix(actual, pred))\n",
    "\n",
    "\n",
    "        import shap\n",
    "        # load the model from disk    \n",
    "        #model = pickle.load(open(filename, 'rb'))    \n",
    "   \n",
    "        from pypmml import Model\n",
    "\n",
    "        model = Model.fromFile(\"LogisticRegression_model.pmml\")\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "if False:\n",
    "        # Variable Importance - Global Interpretability\n",
    "        shap_values = shap.Explainer(model, masker=shap.maskers.Impute(data=X2),\n",
    "                           feature_names=X2.columns, algorithm=\"linear\")\n",
    "       \n",
    "        #shap_values = shap.LinearExplainer(result).shap_values(X)\n",
    "        shap.summary_plot(shap_values, X, plot_type=\"bar\")\n",
    "   \n",
    "   \n",
    "        # positive and negative relationships of the predictors with the target variable\n",
    "        shap.summary_plot(shap_values, X)  \n",
    "\n",
    "\n",
    "       \n",
    "        print(\"Average probabiliyt of being Good: \",str(round(data['Probability'].mean()*100,1)))  \n",
    "        data.to_csv(loc+'generalisatioon.csv')      \n",
    "   \n",
    "   \n",
    "if False:    \n",
    "        data.to_csv(loc+'developmentDataset_with_WOE.csv')\n",
    "       \n",
    "        data['x1']  = round((data['grade']*coe[1]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x2']  = round((data['emp_length']*coe[2]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x3']  = round((data['dti']*coe[3]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x4']  = round((data['Orig_FicoScore']*coe[4]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x5']  = round((data['inq_last_6mths']*coe[5]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x6']  = round((data['acc_open_past_24mths']*coe[6]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x7']  = round((data['mort_acc']*coe[7]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x8']  = round((data['mths_since_recent_bc']*coe[8]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x9']  = round((data['num_rev_tl_bal_gt_0']*coe[9]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x10'] = round((data['percent_bc_gt_75']*coe[10]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "   \n",
    "        data['Score'] = data['x1']+    data['x2']+    data['x3']+    data['x4']+    data['x5']+    data['x6']+    data['x7']+data['x8']+data['x9']+data['x10']\n",
    "        #print(data)\n",
    "        data.to_csv(loc+'_development_scored_data.csv')\n",
    "        print(\"\")\n",
    "        print(\"Average Score of Population: \", str(round(data['Score'].mean(),1)))\n",
    "        g = data.loc[data['Target'] == 1]\n",
    "        print(\"Average Score of Goods: \", str(round(g['Score'].mean(),1)))\n",
    "        g = data.loc[data['Target'] == 0]\n",
    "        print(\"Average Score of Bads: \", str(g['Score'].mean()))\n",
    "        g = data.loc[data['Target'] == -1]\n",
    "        print(\"Average Score of Indeterminates: \", str(round(g['Score'].mean(),1)))\n",
    "   \n",
    "        print(\"\")\n",
    "        print(\"Minimum Score: \",str(data['Score'].min()))\n",
    "        print(\"Average Score: \",str(data['Score'].mean()))\n",
    "        print(\"Maximum Score: \",str(data['Score'].max()))\n",
    "        print(\"\")\n",
    "   \n",
    "        data['ScoreBinned']=pd.cut(data['Score'], bins=[0,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,800,900])\n",
    "        x = pd.crosstab(data['ScoreBinned'],data['Target'])        \n",
    "       \n",
    "        x.to_csv(modelDevelopment+'2015_scaledScoreDistribution.csv')\n",
    "        print(\"The scaled score distribution has been saved here: \",modelDevelopment+'scaledScoreDistribution.csv')\n",
    "        print(\"\")\n",
    "        print(\"Development Scaling completed!\")    \n",
    "\n",
    "if False:    \n",
    "        print(\"#################################################################\")\n",
    "        print(\"#                                                               #\")\n",
    "        print(\"#                   EVALUATE 2016                               #\")\n",
    "        print(\"#                                                               #\")\n",
    "        print(\"#################################################################\")  \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "        data = pd.read_csv(loc+'2016.csv')# input data without WOE values\n",
    "       # data = data.drop(columns=['Unnamed: 0'],axis=1)\n",
    "   \n",
    "        for z in range(len(chars)):\n",
    "            if(data[chars[z]].dtype !='object'):\n",
    "                data[chars[z]] = Series(replace_woe(data[chars[z]], cutList[z], woeList[z]))\n",
    "            else:\n",
    "                data[chars[z]+'_bin'] = (\n",
    "                        data[chars[z]]\n",
    "                        .apply(lambda x: [k for k in binners[z].keys() if x in binners[z][k]])\n",
    "                        .str[0])\n",
    "                data[chars[z]] = Series(replace_woe_str(data[chars[z]+\"_bin\"], cutList[z], woeList[z]))\n",
    "   \n",
    "        data.to_csv(loc+'developmentDataset_with_WOE.csv')\n",
    "       \n",
    "        data['x1']  = round((data['grade']*coe[1]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x2']  = round((data['emp_length']*coe[2]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x3']  = round((data['dti']*coe[3]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x4']  = round((data['Orig_FicoScore']*coe[4]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x5']  = round((data['inq_last_6mths']*coe[5]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x6']  = round((data['acc_open_past_24mths']*coe[6]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x7']  = round((data['mort_acc']*coe[7]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x8']  = round((data['mths_since_recent_bc']*coe[8]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x9']  = round((data['num_rev_tl_bal_gt_0']*coe[9]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x10'] = round((data['percent_bc_gt_75']*coe[10]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "   \n",
    "        data['Score'] = data['x1']+    data['x2']+    data['x3']+    data['x4']+    data['x5']+    data['x6']+    data['x7']+data['x8']+data['x9']+data['x10']\n",
    "        #print(data)\n",
    "        data.to_csv(loc+'_development_scored_data.csv')\n",
    "        print(\"\")\n",
    "        print(\"Average Score of Population: \", str(round(data['Score'].mean(),1)))\n",
    "        g = data.loc[data['Target'] == 1]\n",
    "        print(\"Average Score of Goods: \", str(round(g['Score'].mean(),1)))\n",
    "        g = data.loc[data['Target'] == 0]\n",
    "        print(\"Average Score of Bads: \", str(g['Score'].mean()))\n",
    "        g = data.loc[data['Target'] == -1]\n",
    "        print(\"Average Score of Indeterminates: \", str(round(g['Score'].mean(),1)))\n",
    "   \n",
    "        print(\"\")\n",
    "        print(\"Minimum Score: \",str(data['Score'].min()))\n",
    "        print(\"Average Score: \",str(data['Score'].mean()))\n",
    "        print(\"Maximum Score: \",str(data['Score'].max()))\n",
    "        print(\"\")\n",
    "   \n",
    "        data['ScoreBinned']=pd.cut(data['Score'], bins=[0,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,800,900])\n",
    "        x = pd.crosstab(data['ScoreBinned'],data['Target'])        \n",
    "       \n",
    "        x.to_csv(modelDevelopment+'2016_scaledScoreDistribution.csv')\n",
    "        print(\"The scaled score distribution has been saved here: \",modelDevelopment+'scaledScoreDistribution.csv')\n",
    "        print(\"\")\n",
    "        print(\"Development Scaling completed!\")            \n",
    "       \n",
    "        print(\"#################################################################\")\n",
    "        print(\"#                                                               #\")\n",
    "        print(\"#                   EVALUATE 2017                               #\")\n",
    "        print(\"#                                                               #\")\n",
    "        print(\"#################################################################\")  \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "        data = pd.read_csv(loc+'2017.csv')# input data without WOE values\n",
    "       # data = data.drop(columns=['Unnamed: 0'],axis=1)\n",
    "   \n",
    "        for z in range(len(chars)):\n",
    "           \n",
    "   \n",
    "            if(data[chars[z]].dtype !='object'):\n",
    "                data[chars[z]] = Series(replace_woe(data[chars[z]], cutList[z], woeList[z]))\n",
    "            else:\n",
    "                data[chars[z]+'_bin'] = (\n",
    "                        data[chars[z]]\n",
    "                        .apply(lambda x: [k for k in binners[z].keys() if x in binners[z][k]])\n",
    "                        .str[0])\n",
    "                data[chars[z]] = Series(replace_woe_str(data[chars[z]+\"_bin\"], cutList[z], woeList[z]))\n",
    "   \n",
    "        data.to_csv(loc+'developmentDataset_with_WOE.csv')\n",
    "       \n",
    "        data['x1']  = round((data['grade']*coe[1]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x2']  = round((data['emp_length']*coe[2]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x3']  = round((data['dti']*coe[3]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x4']  = round((data['Orig_FicoScore']*coe[4]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x5']  = round((data['inq_last_6mths']*coe[5]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x6']  = round((data['acc_open_past_24mths']*coe[6]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x7']  = round((data['mort_acc']*coe[7]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x8']  = round((data['mths_since_recent_bc']*coe[8]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x9']  = round((data['num_rev_tl_bal_gt_0']*coe[9]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x10'] = round((data['percent_bc_gt_75']*coe[10]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "   \n",
    "        data['Score'] = data['x1']+    data['x2']+    data['x3']+    data['x4']+    data['x5']+    data['x6']+    data['x7']+data['x8']+data['x9']+data['x10']\n",
    "        #print(data)\n",
    "        data.to_csv(loc+'_development_scored_data.csv')\n",
    "        print(\"\")\n",
    "        print(\"Average Score of Population: \", str(round(data['Score'].mean(),1)))\n",
    "        g = data.loc[data['Target'] == 1]\n",
    "        print(\"Average Score of Goods: \", str(round(g['Score'].mean(),1)))\n",
    "        g = data.loc[data['Target'] == 0]\n",
    "        print(\"Average Score of Bads: \", str(g['Score'].mean()))\n",
    "        g = data.loc[data['Target'] == -1]\n",
    "        print(\"Average Score of Indeterminates: \", str(round(g['Score'].mean(),1)))\n",
    "   \n",
    "        print(\"\")\n",
    "        print(\"Minimum Score: \",str(data['Score'].min()))\n",
    "        print(\"Average Score: \",str(data['Score'].mean()))\n",
    "        print(\"Maximum Score: \",str(data['Score'].max()))\n",
    "        print(\"\")\n",
    "   \n",
    "        data['ScoreBinned']=pd.cut(data['Score'], bins=[0,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,800,900])\n",
    "        x = pd.crosstab(data['ScoreBinned'],data['Target'])        \n",
    "       \n",
    "        x.to_csv(modelDevelopment+'2017_scaledScoreDistribution.csv')\n",
    "        print(\"The scaled score distribution has been saved here: \",modelDevelopment+'scaledScoreDistribution.csv')\n",
    "        print(\"\")\n",
    "        print(\"Development Scaling completed!\")            \n",
    "       \n",
    "       \n",
    "        print(\"#################################################################\")\n",
    "        print(\"#                                                               #\")\n",
    "        print(\"#                   EVALUATE 2018                               #\")\n",
    "        print(\"#                                                               #\")\n",
    "        print(\"#################################################################\")  \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "        data = pd.read_csv(loc+'2018.csv')# input data without WOE values\n",
    "       # data = data.drop(columns=['Unnamed: 0'],axis=1)\n",
    "   \n",
    "        for z in range(len(chars)):\n",
    "           \n",
    "   \n",
    "            if(data[chars[z]].dtype !='object'):\n",
    "                data[chars[z]] = Series(replace_woe(data[chars[z]], cutList[z], woeList[z]))\n",
    "            else:\n",
    "                data[chars[z]+'_bin'] = (\n",
    "                        data[chars[z]]\n",
    "                        .apply(lambda x: [k for k in binners[z].keys() if x in binners[z][k]])\n",
    "                        .str[0])\n",
    "                data[chars[z]] = Series(replace_woe_str(data[chars[z]+\"_bin\"], cutList[z], woeList[z]))\n",
    "   \n",
    "        data.to_csv(loc+'developmentDataset_with_WOE.csv')\n",
    "       \n",
    "        data['x1']  = round((data['grade']*coe[1]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x2']  = round((data['emp_length']*coe[2]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x3']  = round((data['dti']*coe[3]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x4']  = round((data['Orig_FicoScore']*coe[4]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x5']  = round((data['inq_last_6mths']*coe[5]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x6']  = round((data['acc_open_past_24mths']*coe[6]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x7']  = round((data['mort_acc']*coe[7]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x8']  = round((data['mths_since_recent_bc']*coe[8]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x9']  = round((data['num_rev_tl_bal_gt_0']*coe[9]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "        data['x10'] = round((data['percent_bc_gt_75']*coe[10]+(coe[0]/10))*Factor+(Offset/10),0)\n",
    "   \n",
    "        data['Score'] = data['x1']+    data['x2']+    data['x3']+    data['x4']+    data['x5']+    data['x6']+    data['x7']+data['x8']+data['x9']+data['x10']\n",
    "        #print(data)\n",
    "        data.to_csv(loc+'_development_scored_data.csv')\n",
    "        print(\"\")\n",
    "        print(\"Average Score of Population: \", str(round(data['Score'].mean(),1)))\n",
    "        g = data.loc[data['Target'] == 1]\n",
    "        print(\"Average Score of Goods: \", str(round(g['Score'].mean(),1)))\n",
    "        g = data.loc[data['Target'] == 0]\n",
    "        print(\"Average Score of Bads: \", str(g['Score'].mean()))\n",
    "        g = data.loc[data['Target'] == -1]\n",
    "        print(\"Average Score of Indeterminates: \", str(round(g['Score'].mean(),1)))\n",
    "   \n",
    "        print(\"\")\n",
    "        print(\"Minimum Score: \",str(data['Score'].min()))\n",
    "        print(\"Average Score: \",str(data['Score'].mean()))\n",
    "        print(\"Maximum Score: \",str(data['Score'].max()))\n",
    "        print(\"\")\n",
    "   \n",
    "        data['ScoreBinned']=pd.cut(data['Score'], bins=[0,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,800,900])\n",
    "        x = pd.crosstab(data['ScoreBinned'],data['Target'])        \n",
    "       \n",
    "        x.to_csv(modelDevelopment+'2018_scaledScoreDistribution.csv')\n",
    "        print(\"The scaled score distribution has been saved here: \",modelDevelopment+'scaledScoreDistribution.csv')\n",
    "        print(\"\")\n",
    "        print(\"Development Scaling completed!\")            \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
